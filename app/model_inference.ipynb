{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "\n",
    "from skimage.io import imread\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "from skimage.morphology import label\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "##Dice coefficient\n",
    "def dice_coef(y_true, y_pred, smooth=0.0001):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = K.sum(y_true, axis=[1, 2, 3]) + K.sum(y_pred, axis=[1, 2, 3])\n",
    "    return K.mean((2.0 * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3 * binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "\n",
    "test_image_dir = '../data/test_samples/'\n",
    "\n",
    "# loading needed model\n",
    "model = load_model(\"app/segmentation_model.h5\", custom_objects={'dice_coef':dice_coef,'dice_p_bce':                   \n",
    "dice_p_bce})\n",
    "\n",
    "# Run the test data\n",
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), \"test images found\")\n",
    "\n",
    "def multi_rle_encode(img):\n",
    "    \"\"\"\n",
    "    Encode connected regions as separated masks\n",
    "    \"\"\"\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels == k) for k in np.unique(labels[labels > 0])]\n",
    "\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    \"\"\"\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    \"\"\"\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    \"\"\"\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    \"\"\"\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype=np.float32)\n",
    "    # if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)\n",
    "\n",
    "\n",
    "def raw_prediction(img, path=test_image_dir):\n",
    "    c_img = imread(os.path.join(path, img))\n",
    "    c_img = np.expand_dims(c_img, 0) / 255.0\n",
    "    cur_seg = model.predict(c_img)[0]\n",
    "    return cur_seg, c_img[0]\n",
    "\n",
    "\n",
    "def pred_encode(img):\n",
    "    cur_seg, _ = raw_prediction(img)\n",
    "    cur_rles = multi_rle_encode(cur_seg)\n",
    "    return [[img, rle] for rle in cur_rles if rle is not None]\n",
    "\n",
    "\n",
    "out_pred_rows = []\n",
    "for c_img_name in tqdm(test_paths):\n",
    "    out_pred_rows += pred_encode(c_img_name)\n",
    "\n",
    "sub = pd.DataFrame(out_pred_rows)\n",
    "sub.columns = [\"ImageId\", \"EncodedPixels\"]\n",
    "sub = sub[sub.EncodedPixels.notnull()]\n",
    "sub.head()\n",
    "\n",
    "TOP_PREDICTIONS=5\n",
    "fig, m_axs = plt.subplots(TOP_PREDICTIONS, 2, figsize = (9, TOP_PREDICTIONS*5))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "\n",
    "for (ax1, ax2), c_img_name in zip(m_axs, sub.ImageId.unique()[:TOP_PREDICTIONS]):\n",
    "    c_img = imread(os.path.join(test_image_dir, c_img_name))\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    ax1.imshow(c_img[0])\n",
    "    ax1.set_title('Image: ' + c_img_name)\n",
    "    ax2.imshow(masks_as_image(sub.query('ImageId==\"{}\"'.format(c_img_name))['EncodedPixels']))\n",
    "    ax2.set_title('Prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
